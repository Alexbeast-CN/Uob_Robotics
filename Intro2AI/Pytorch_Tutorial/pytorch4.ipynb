{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 4. 训练神经网络 (Training our Neural Network)\n",
    "\n",
    "在上一个教程中，我们为我们的神经网络创建了代码。在这个使用 Python 和 Pytorch 进行深度学习的教程中，我们将通过学习如何迭代我们的数据、传递给模型、从结果中计算损失，然后进行反向传播以使我们的模型慢慢适应数据。\n",
    "\n",
    "在之前的文章中，我们已经完成以下部分的代码：\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=64, bias=True)\n",
      "  (fc2): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc3): Linear(in_features=64, out_features=64, bias=True)\n",
      "  (fc4): Linear(in_features=64, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torchvision\n",
    "from torchvision import transforms, datasets\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "train = datasets.MNIST('', train=True, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "test = datasets.MNIST('', train=False, download=True,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor()\n",
    "                       ]))\n",
    "\n",
    "\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)\n",
    "\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 64)\n",
    "        self.fc2 = nn.Linear(64, 64)\n",
    "        self.fc3 = nn.Linear(64, 64)\n",
    "        self.fc4 = nn.Linear(64, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = F.relu(self.fc3(x))\n",
    "        x = self.fc4(x)\n",
    "        return F.log_softmax(x, dim=1)\n",
    "\n",
    "net = Net()\n",
    "print(net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 反向传播\n",
    "\n",
    "### 1.1 优化器(optimizer)\n",
    "\n",
    "对我们来说幸运的是， Pytorch 使用的“数据”实际上已经分批了，我们只需要迭代它。接下来，我们要计算损失并指定我们的优化器："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.optim as optim\n",
    "\n",
    "loss_function = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(net.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 损失函数(loss_function)\n",
    "\n",
    "损失函数 `loss_function` 用于计算我们的分类与现实的之间的差距。作为人类，我们倾向于根据对或错来思考事物。但神经网络，则是已经一件事物的可能性来判断事情。就机器学习而言，为了使得模型准确，需要通过调整大量的参数以逐渐接近拟合。为此，我们使用损失`loss`，这是衡量神经网络与目标输出的距离。损失计算的方法有很多种。一种比较流行的方法是使用均方误差。\n",
    "\n",
    "$$\n",
    "MSE = \\frac{\\sum_{i=1}^n(y_i - \\hat{y}_i)^2}{N}\n",
    "$$\n",
    "\n",
    "由于我们的例子是一个分类问题，因此这里我们使用的损失函数是 `nll_loss`\n",
    "\n",
    "对于数据类别的表示方式一般有两种，一种是标量式，另外一种是 `one_hot vector` 向量式，比如：\n",
    "\n",
    "$$\n",
    "0 \\\\ or \\\\\n",
    "\\begin{bmatrix}\n",
    "    1 & 0 & 0 & 0 & 0 & 0 & 0 & 0\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "`one_hot vector` 是一个二进制的向量，其中的每一个元素都是 0 或 1，比如：3 可以表示为：\n",
    "\n",
    "$$\n",
    "\\begin{bmatrix}\n",
    "    0 & 0 & 0 & 3 & 0 & 0 & 0 & 0\\\\\n",
    "\\end{bmatrix}\n",
    "$$\n",
    "\n",
    "接下来，我们需要一个优化器，这里我们使用的是 `Adam` 优化器，它是一种比较流行的优化器。`Adam` 可以自适应动量和梯度，这样可以避免梯度爆炸的问题。在将这个之前，我们先来了解一下学习率 `learning_rate`，这是一个可以调整的参数，它决定了模型学习的速度。过快会出现反复横跳，过慢训练时间就会很长。\n",
    "\n",
    "![ ](./pics/leanring.jpg)\n",
    "\n",
    "通常来说，我们希望学习率先大后小，这样可以帮助我们的模型快速找到最优解附近，然后在该点位附近慢慢的找到最优点。\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 时期 (epoch)\n",
    "\n",
    "现在我们可以迭代我们的数据。通常，您将不止一次通过整个训练数据集。数据集的每一次完整传递都称为一个时期 (`epoch`)。一般来说，你可能会有 3 到 10 个 `epoch` ，但这里没有硬性规定。时期太少，模型不会学习完所有的数据。时期太多，模型可能会过度拟合您的样本内数据（基本上记住样本内数据，但在样本外数据上表现不佳）。\n",
    "\n",
    "现在让我们使用 3 个 `epoch` 。所以我们将循环遍历 `epoch` ，每个 `epoch` 都会遍历我们的数据。就像是："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(0.0348, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.0033, grad_fn=<NllLossBackward0>)\n",
      "tensor(0.1283, grad_fn=<NllLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(3): # 3 full passes over the data\n",
    "    for data in trainset:  # `data` is a batch of data\n",
    "        X, y = data  # X is the batch of features, y is the batch of targets.\n",
    "        net.zero_grad()  # sets gradients to 0 before loss calc. You will do this likely every step.\n",
    "        output = net(X.view(-1,784))  # pass in the reshaped batch (recall they are 28x28 atm)\n",
    "        loss = F.nll_loss(output, y)  # calc and grab the loss value\n",
    "        loss.backward()  # apply this loss backwards thru the network's parameters\n",
    "        optimizer.step()  # attempt to optimize weights to account for loss/gradients\n",
    "    print(loss)  # print loss. We hope loss (a measure of wrong-ness) declines! "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.4 总结\n",
    "\n",
    "在上面的代码中，有一行 `net.zero_grad()` 在每一批次数据通过之后，将梯度设置为零，下一批次的数据将在之前已经优化过的模型上，从新开始梯度下降。下面我们来总结一下在一个批次中，我们让神经网络做了什么：\n",
    "\n",
    "- 从当前批次中获取特征 (X) 和标签 (y)\n",
    "- 将梯度归零 (net.zero_grad)\n",
    "- 通过网络传递数据\n",
    "- 计算损失\n",
    "- 调整网络中的权重以减少损失"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 验证模型\n",
    "\n",
    "当我们迭代时，我们会得到损失值，这是一个重要的指标，但我们关心的是准确性。那么，我们是怎么做的呢？为了测试这一点，我们需要做的就是迭代我们的测试集，通过将输出与目标值进行比较来测量正确性。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy:  0.967\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data in testset:\n",
    "        X, y = data\n",
    "        output = net(X.view(-1,784))\n",
    "        #print(output)\n",
    "        for idx, i in enumerate(output):\n",
    "            #print(torch.argmax(i), y[idx])\n",
    "            if torch.argmax(i) == y[idx]:\n",
    "                correct += 1\n",
    "            total += 1\n",
    "\n",
    "print(\"Accuracy: \", round(correct/total, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果看起来还不错，准确率达到了 0.967。光有准确率还不够直观，下面我们将图片和结果打印出来，看一下结果是否正确："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(2)\n",
      "tensor(0)\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# randomly select a few images from the test set and plot them\n",
    "plt.subplot(1,2,1)\n",
    "plt.imshow(X[5].view(28,28))\n",
    "\n",
    "plt.subplot(1,2,2)\n",
    "plt.imshow(X[3].view(28,28))\n",
    "plt.show()\n",
    "\n",
    "print(torch.argmax(net(X[5].view(-1,784))[0]))\n",
    "print(torch.argmax(net(X[3].view(-1,784))[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-2.5393e+01, -1.7943e+01, -1.1810e+01, -1.5074e+01, -2.7140e+01,\n",
      "        -2.0390e+01, -3.6855e+01, -7.7486e-06, -2.1229e+01, -1.8540e+01],\n",
      "       grad_fn=<SelectBackward0>)\n"
     ]
    }
   ],
   "source": [
    "a_featureset = X[0]\n",
    "reshaped_for_network = a_featureset.view(-1,784) # 784 b/c 28*28 image resolution.\n",
    "output = net(reshaped_for_network) #output will be a list of network predictions.\n",
    "first_pred = output[0]\n",
    "print(first_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "哪个指标值最大？我们使用 `argmax` 来找到这个："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(7)\n"
     ]
    }
   ],
   "source": [
    "biggest_index = torch.argmax(first_pred)\n",
    "print(biggest_index)"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "c6d9031e658debb2ea8943e06a648314df12deac922ea91a3af9df8928bf1d5c"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('base': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
