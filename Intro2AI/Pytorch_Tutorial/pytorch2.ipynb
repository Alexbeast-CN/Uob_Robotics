{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pytorch 2. 数据集\n",
    "\n",
    "我们首先要考虑的是我们的数据。在大多数教程中，为了直接进行神经网络的训练，这一点经常被忽略。但作为一个程序员，最大的任务之一就是预处理数据并以最容易让神经网络使用的方式对其进行格式化。虽然这是一个比较没有难度的时候，进行学习的大多数时间要么在收集和处理数据，要么在等神经网络的训练。所以，在开始讲解神经网络之前，先让我们进行数据处理。"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 创建数据集\n",
    "\n",
    "因为是学习用，所以这里的数据集选择一个现成的数据集： `torchvision`torchvision 是一个用于视觉任务的数据集。下面开始操作：\n",
    "\n",
    "首先导入数据集的库："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# if you don't have torchvision, you can install it by:\n",
    "# pip install torchvision\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "from torchvision import  transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们使用 torchvision 来加载 MNIST 数据集，这是一个基于图像的数据集，显示 0-9 的手写数字，你的工作是编写一个神经网络来对它们进行分类。不过在此之前，我们先将数据此数据集分为 `train` 和 `test` 两个部分。在执行这个步骤的时候，我们需要将数据强制转换成 `tensor` 格式，方便 `pytorch` 处理。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = datasets.MNIST(root='./data', train=True, transform=transforms.Compose([transforms.ToTensor()]), download=True)\n",
    "test = datasets.MNIST(root='./data', train=False, transform=transforms.Compose([transforms.ToTensor()]), download=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将数据集分好后，我们会再将数据分组 (`batch_size=10`)，并且一组一组的喂给模型进行训练。之所以不将所有数据一次性都喂给机器是因为：\n",
    "\n",
    "- 有时候数据集太大了，10+GB, 100+GB 的都有。但是通常 GPU 的 RAM 没有那么大\n",
    "- 另外机器学习中最快的学习方法就是记忆。但是 RAM 是有限的，而测试时出现的情况几乎是无限的。所以让机械学习每次只读取少量的数据，可以让模型不断的调整其中的参数，从而达到对于一般情况都额能够准确识别的能力。\n",
    "\n",
    "然后，在我们的训练数据集中，我们通常希望尽可能地随机打乱输入数据，希望数据中没有任何可能导致机器停机的模式。(`shuffle=True`) 防止在训练时出现连续多个数据都是同一个类别的情况，因为这样的情况容易让机器将所有图片都分到那个它经常见到的类别之中。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# batch_size is the number data we want to feed to the network each time\n",
    "# shuffle make the model to learn the data in random order\n",
    "trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)\n",
    "testset = torch.utils.data.DataLoader(test, batch_size=10, shuffle=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 使用数据\n",
    "\n",
    "好吧，我们有了数据，但我们如何使用它？\n",
    "\n",
    "一个简单的操作是可以像这样迭代数据："
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[tensor([[[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        ...,\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]],\n",
      "\n",
      "\n",
      "        [[[0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          ...,\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.],\n",
      "          [0., 0., 0.,  ..., 0., 0., 0.]]]]), tensor([3, 0, 8, 2, 2, 4, 8, 1, 6, 4])]\n"
     ]
    }
   ],
   "source": [
    "for data in trainset:\n",
    "    print(data)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每次迭代将包含一批 10 个元素（这是我们选择的批量大小）和 10 个类。我们来看一下其中一个组数据：（data[0] 是一堆事物的特征，而 data[1] 是所有的目标。）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(3)\n"
     ]
    }
   ],
   "source": [
    "x, y = data[0][0], data[1][0]\n",
    "\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "如您所见， data[1] 只是一堆标签。因此，由于 data[1][0] 是 3，我们可以预期 data[0][0] 是 3 的图像。让我们看看！"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "print(data[0][0].shape)\n",
    "# This is a 28x28 image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(data[0][0].view(28,28), cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "下面我们来查看一下训练集中每一个标签都有多少数据。这里我使用了一个 词典 的数据结构来表示结果。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: 5923, 1: 6742, 2: 5958, 3: 6131, 4: 5842, 5: 5421, 6: 5918, 7: 6265, 8: 5851, 9: 5949}\n"
     ]
    }
   ],
   "source": [
    "# Iterate through the dataset\n",
    "\n",
    "# We want the dataset to be as balanced as possible\n",
    "\n",
    "total = 0\n",
    "counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}\n",
    "\n",
    "for data in trainset:\n",
    "    Xs, ys = data\n",
    "    for y in ys:\n",
    "        counter_dict[int(y)]+=1\n",
    "        total +=1\n",
    "\n",
    "print(counter_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 数据平衡\n",
    "\n",
    "对于我们的模型来说，好的训练需要好的数据。数据平衡是其中一项指标。\n",
    "\n",
    "想象一下，你有一个猫和狗的数据集。 7200 张图片是狗，1800 张是猫。 这是相当不平衡的。 分类器很可能会发现，通过简单的总是预测狗，它可以非常快速轻松地达到 72% 的准确率。 该模型极不可能从这种情况中恢复。\n",
    "\n",
    "其他时候，这种不平衡并不那么严重，但仍然足以使模型几乎总是以某种方式预测，除非在最明显的情况下。 无论如何，如果我们能平衡数据集是最好的。\n",
    "\n",
    "通过“平衡”，我的意思是确保训练中的每个分类都有相同数量的示例。\n",
    "\n",
    "这个要做起来其实很简单，就是通过我们上一步的数据计数来完成。下面只是将比例打出来了，可以看出来，这个数据的分类还是比较均匀的。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0: 0.9871666666666666\n",
      "1: 1.1236666666666668\n",
      "2: 0.993\n",
      "3: 1.0218333333333334\n",
      "4: 0.9736666666666667\n",
      "5: 0.9035\n",
      "6: 0.9863333333333334\n",
      "7: 1.0441666666666667\n",
      "8: 0.9751666666666667\n",
      "9: 0.9915\n"
     ]
    }
   ],
   "source": [
    "for i in counter_dict:\n",
    "    print(f\"{i}: {counter_dict[i]/total*10}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
