{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iwu81dwqLB4M"
      },
      "source": [
        "# Play Atari games using baselines3\n",
        "\n",
        "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/drive/1n0kyQJMHU2TTb-cZS0BgHAJsBfFg_AYh?usp=sharing) [![Open In Github](https://badgen.net/badge/Open%20Source%20%3F/Yes%21/blue?icon=github)](https://github.com/Alexbeast-CN/Uob_Robotics/tree/main/DRL/PWG/PWG2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ltohTFgbLHgC"
      },
      "source": [
        "## 1. Preparations\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xkn5ZuJIOltD"
      },
      "source": [
        "### All parameters for this notebook"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Djxa-QioOiRH"
      },
      "outputs": [],
      "source": [
        "ENVIRONMENT = \"SpaceInvaders-v0\"\n",
        "PATH = \"/content/drive/MyDrive/Reinforcement_Learning/SpaceInvaders2\"\n",
        "GAMMA = 0.99           # discount factor\n",
        "# This buffer requires about 25G RAM\n",
        "BUFFER_SIZE = 100000   # replay buffer size\n",
        "BATCH_SIZE = 32        # Update batch size\n",
        "LR = 0.0001            # learning rate \n",
        "TAU = 0.1               # for soft update of target parameters\n",
        "UPDATE_EVERY = 100     # how often to update the network\n",
        "UPDATE_TARGET = 10000  # After which thershold replay to be started \n",
        "EPS_START = 0.99       # starting value of epsilon\n",
        "EPS_END = 0.01         # Ending value of epsilon\n",
        "EPS_DECAY = 0.01        # Rate by which epsilon to be decayed\n",
        "\n",
        "LOAD_MODEL = False\n",
        "MODEL_NUMBER = 9\n",
        "MODEL_PATH = PATH+f\"/model_{MODEL_NUMBER}\"\n",
        "\n",
        "TRAINING = True\n",
        "DISPLAY = True\n",
        "COLAB = True"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ESg9BF37Oj7v"
      },
      "source": [
        "### [For Colab] Install ROM for Atari games"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "d7IpuuIKLBGN"
      },
      "outputs": [],
      "source": [
        "if COLAB:\n",
        "  # use %%capture to hide the output\n",
        "  %%capture\n",
        "  ! wget http://www.atarimania.com/roms/Roms.rar\n",
        "  ! mkdir /content/ROM/\n",
        "  ! unrar e /content/Roms.rar /content/ROM/ -y\n",
        "  ! python -m atari_py.import_roms /content/ROM/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PHB3_K8kMEQw"
      },
      "source": [
        "### [For Colab] Mount Google Drive to this notebook for saving model and logs"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "8deWKo43MDyU",
        "outputId": "81818869-d9ae-4b0f-bffe-46cd01c3d1fd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "if COLAB:\n",
        "  from google.colab import drive\n",
        "  drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MmKmz9DSMYm4"
      },
      "source": [
        "### Save videos\n",
        "\n",
        "In colab the game play can't be properly displayed, therefore we need to save the rendered game play into videos for test check."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uC6fxBOhMeiZ"
      },
      "outputs": [],
      "source": [
        "if COLAB:\n",
        "  %%capture\n",
        "  !pip install gym pyvirtualdisplay > /dev/null 2>&1\n",
        "  !apt-get install -y xvfb python-opengl ffmpeg > /dev/null 2>&1\n",
        "else:\n",
        "  %%capture\n",
        "  !pip install gym pyvirtualdisplay \n",
        "  !apt-get install -y xvfb python-opengl ffmpeg "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "08EF8L72NOM4"
      },
      "outputs": [],
      "source": [
        "import gym\n",
        "from gym.wrappers import Monitor\n",
        "import glob\n",
        "import io\n",
        "import base64\n",
        "from IPython.display import HTML\n",
        "from pyvirtualdisplay import Display\n",
        "from IPython import display as ipythondisplay\n",
        "display = Display(visible=0, size=(1400, 900))\n",
        "display.start()\n",
        "\n",
        "\"\"\"\n",
        "Utility functions to enable video recording of gym environment \n",
        "and displaying it.\n",
        "To enable video, just do \"env = wrap_env(env)\"\"\n",
        "\"\"\"\n",
        "\n",
        "def show_video():\n",
        "  # Save the video to your google drive path\n",
        "  mp4list = glob.glob('video/*.mp4')\n",
        "  if len(mp4list) > 0:\n",
        "    mp4 = mp4list[0]\n",
        "    video = io.open(mp4, 'r+b').read()\n",
        "    encoded = base64.b64encode(video)\n",
        "    ipythondisplay.display(HTML(data='''<video alt=\"test\" autoplay \n",
        "                loop controls style=\"height: 400px;\">\n",
        "                <source src=\"data:video/mp4;base64,{0}\" type=\"video/mp4\" />\n",
        "             </video>'''.format(encoded.decode('ascii'))))\n",
        "  else: \n",
        "    print(\"Could not find video\")\n",
        "\n",
        "def wrap_env(env):\n",
        "  env = Monitor(env, './video', force=True)\n",
        "  return env"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PUF0TbNnW4Kd"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "QYZAIZffKria"
      },
      "source": [
        "## 2. Create a model and start training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROEuBgUjKvir"
      },
      "outputs": [],
      "source": [
        "%%capture\n",
        "!pip install stable-baselines3[extra]\n",
        "# import the dqn model form stable-baselines\n",
        "from stable_baselines3 import DQN\n",
        "# DummyVecEnv can help train multiple agents at the same time\n",
        "from stable_baselines3.common.vec_env import DummyVecEnv\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UWIxJWbA75Je"
      },
      "outputs": [],
      "source": [
        "# Create multi-envirnoment\n",
        "env = gym.make(ENVIRONMENT)\n",
        "env = DummyVecEnv([lambda: env])\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lZb0A0QJc2eu"
      },
      "outputs": [],
      "source": [
        "if LOAD_MODEL:\n",
        "  model = DQN.load(MODEL_PATH,env=env)\n",
        "else:\n",
        "  # Create a DQN model\n",
        "  model = DQN('CnnPolicy', \n",
        "            env, learning_rate=LR, \n",
        "            buffer_size=BUFFER_SIZE, \n",
        "            learning_starts=UPDATE_TARGET, \n",
        "            batch_size=BATCH_SIZE, tau=TAU, \n",
        "            gamma= GAMMA, \n",
        "            target_update_interval=UPDATE_EVERY, \n",
        "            exploration_fraction=EPS_DECAY, \n",
        "            exploration_initial_eps=EPS_START, \n",
        "            exploration_final_eps=EPS_END, \n",
        "            tensorboard_log=PATH)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "tjBnFGWvh94G"
      },
      "source": [
        "Train the model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mIrwPvWmmCRz",
        "outputId": "4b135790-974e-45cb-9e86-f8b148db5d58"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model 30 is under training...\n",
            "Model 31 is under training...\n",
            "Model 32 is under training...\n",
            "Model 33 is under training...\n",
            "Model 34 is under training...\n",
            "Model 35 is under training...\n",
            "Model 36 is under training...\n",
            "Model 37 is under training...\n",
            "Model 38 is under training...\n",
            "Model 39 is under training...\n"
          ]
        }
      ],
      "source": [
        "if TRAINING:\n",
        "  for i in range(30,40):\n",
        "      model.learn(total_timesteps=100000)\n",
        "      model.save(f\"{PATH}/model_{i}\")\n",
        "      print(f\"Model {i} is under training...\")\n",
        "  env.close()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qYnDp2JvsgOw"
      },
      "source": [
        "## 3. Display the result"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OoT82Z3k8Ui5"
      },
      "outputs": [],
      "source": [
        "if DISPLAY:\n",
        "  episodes = 5\n",
        "  # Loop the env for 5 episodes\n",
        "  for episode in range(episodes):\n",
        "    env = wrap_env(gym.make(ENVIRONMENT))\n",
        "\n",
        "    # Initialize the environment and get first state\n",
        "    obs = env.reset()\n",
        "    done = False\n",
        "    sorce = 0\n",
        "\n",
        "    while not done:\n",
        "        env.render(mode='rgb_array')\n",
        "        action, _ = model.predict(obs)\n",
        "        obs, reward, done, info = env.step(action)\n",
        "        sorce += reward\n",
        "    print(\"Episode {}  score: {}\".format(episode, sorce))\n",
        "    env.close()\n",
        "    show_video()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "name": "BL3_Atari",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
